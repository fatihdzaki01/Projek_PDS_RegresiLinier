{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatihdzaki01/Projek_PDS_RegresiLinier/blob/DarellX/projek_pds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqOj9js-bZYc"
      },
      "source": [
        "# 1. membuat model berdasarkan korelasi terbesar, Multikol terkecil\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYNF9apCo_wj"
      },
      "source": [
        "## 1.1 IMPORT LIBRARY AND LOAD DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NjkwbsNbgkS"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqUMrOsyOmnR"
      },
      "outputs": [],
      "source": [
        "#Import Library yang Dibutuhkan\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "from folium import Choropleth\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "from scipy.stats import shapiro\n",
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "# tampilkan semua kolom\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY7oN6MDO3m-"
      },
      "outputs": [],
      "source": [
        "# --- Import Data ---\n",
        "df = pd.read_csv(\"air_quality.csv\")\n",
        "\n",
        "# lihat 5 baris pertama\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFCBdZw3tuP7"
      },
      "outputs": [],
      "source": [
        "#lakukan pengarsipan\n",
        "df_raw = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of-gC8P2pKei"
      },
      "source": [
        "## 1.2 DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO9tSfhmpUXI"
      },
      "source": [
        "### 1.2.1 Eksplorasi awal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HunRNbR6POxQ"
      },
      "outputs": [],
      "source": [
        "#Eksplorasi Awal\n",
        "df.info()\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lyL5WBSr_mz"
      },
      "source": [
        "### 1.2.2 Penyesuaian Tipe Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNyezvm-sDRD"
      },
      "outputs": [],
      "source": [
        "# lihat tipe data yang sekarang\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQhSQuF_sUEd"
      },
      "outputs": [],
      "source": [
        "# ubah beberapa kolom menjadi numerik\n",
        "cols_num = ['aqi', 'so2', 'co', 'o3', 'o3_8hr', 'pm10', 'pm2.5', 'no2',\n",
        "             'nox', 'no', 'windspeed', 'winddirec', 'co_8hr',\n",
        "             'pm2.5_avg', 'pm10_avg', 'so2_avg']\n",
        "\n",
        "for c in cols_num:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs0mIjWDszrd"
      },
      "outputs": [],
      "source": [
        "# ubah tipedata kolom 'date' menjadi date\n",
        "df['date'] = pd.to_datetime(df['date'], format='mixed', errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9iIhdB1tQJi"
      },
      "outputs": [],
      "source": [
        "# cek kembali tipedata , untuk memastikan sudah sesuai\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LlmE1xWpkJD"
      },
      "source": [
        "### 1.2.3 Cek Missing Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4W8StWKpQjxT"
      },
      "outputs": [],
      "source": [
        "# cek missing value\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utcslJsztuP9"
      },
      "source": [
        "lakukan penghapusan row dimana longitude, latitude dan siteid nya NULL, karena tidak bisa dilakukan visualisasi MAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUmtyEWPtuP9"
      },
      "outputs": [],
      "source": [
        "# hapus row dengan kolom longitude, latitude dan siteid NULL, karena tidak bisa dibuat visualisasi map\n",
        "id_cols = ['longitude', 'latitude', 'siteid']\n",
        "for c in id_cols:\n",
        "    if c in df.columns:\n",
        "        df = df.dropna(subset=[c])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqvvAkkEfoaN"
      },
      "outputs": [],
      "source": [
        "# persentase missing value\n",
        "(df.isnull().sum() / len(df)) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Su59A3Vp51f"
      },
      "source": [
        "karena kolom 'pollutant' dan 'unit' memiliki persentase missing value cukup besar (> 50%) maka kolom tersebut kami hapus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6oq55rdqEfS"
      },
      "outputs": [],
      "source": [
        "# hapus kolom pollutant dan unit\n",
        "df.drop(columns=['unit', 'pollutant'], inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMa2_Xdjqued"
      },
      "source": [
        "untuk menentukan apakah missing value di isi menggunakan median atau mean, wajib melihat outlier dan distribusinya. jika berdistribusi normal, maka sebaiknya menggunakan mean, jika tidak berdistribusi normal dan punya banyak outlier maka menggunakan median"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1t0ynIwbnJ1"
      },
      "source": [
        "### 1.2.4 cek outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EH9qCA0rsnt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Pilih kolom numerik\n",
        "numeric_cols = df.select_dtypes(include=['float64']).columns\n",
        "\n",
        "n_cols = 3  # jumlah kolom di grid\n",
        "n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
        "\n",
        "# Buat figure\n",
        "plt.figure(figsize=(n_cols * 5, n_rows * 4))\n",
        "\n",
        "# Loop tiap kolom dan plot boxplot-nya\n",
        "for i, col in enumerate(numeric_cols, 1):\n",
        "    plt.subplot(n_rows, n_cols, i)\n",
        "    plt.boxplot(df[col].dropna(), vert=True)\n",
        "    plt.title(col)\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiGO048ruCRx"
      },
      "source": [
        "karena hampir semua kolom memilki nilai outlier, oleh karena itu pengisian missing value menggunakan nilai median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu_Pg8XRuZEH"
      },
      "outputs": [],
      "source": [
        "# Isi missing value pada kolom numerik dgn median karena lebih tahan terhadap outlier dibanding mean\n",
        "for c in cols_num:\n",
        "    if c in df.columns:\n",
        "        median_value = df[c].median()\n",
        "        df[c] = df[c].fillna(median_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNGM3xIKu7ic"
      },
      "outputs": [],
      "source": [
        "# menangani kolom status\n",
        "# cek nilai unique\n",
        "df['status'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYHrKFf8vDcE"
      },
      "outputs": [],
      "source": [
        "df.groupby('status')['aqi'].agg(['min', 'max']).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1TrN11YvKD8"
      },
      "outputs": [],
      "source": [
        "# fungsi untuk menentukan status berdasarkan nilai AQI\n",
        "def categorize_aqi(aqi):\n",
        "    if pd.isna(aqi):\n",
        "        return None\n",
        "    elif 0 <= aqi <= 50:\n",
        "        return 'Good'\n",
        "    elif 51 <= aqi <= 100:\n",
        "        return 'Moderate'\n",
        "    elif 101 <= aqi <= 150:\n",
        "        return 'Unhealthy for Sensitive Groups'\n",
        "    elif 151 <= aqi <= 200:\n",
        "        return 'Unhealthy'\n",
        "    elif 201 <= aqi <= 300:\n",
        "        return 'Very Unhealthy'\n",
        "    elif aqi >= 301:\n",
        "        return 'Hazardous'\n",
        "    else:\n",
        "        return 'Unknown'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HwHjo-5tuP-"
      },
      "outputs": [],
      "source": [
        "df['status'] = df.apply(\n",
        "    lambda row: categorize_aqi(row['aqi']) if pd.isna(row['status']) else row['status'],\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEGnm5Q9uvjh"
      },
      "outputs": [],
      "source": [
        "# --- Cek hasil akhir ---\n",
        "print(\"Missing values setelah pembersihan:\\n\", df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oEUkmO8tuP_"
      },
      "outputs": [],
      "source": [
        "#lakukan pengarsipan untuk missing value\n",
        "df_missingvalue = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0dwzq7tv5fz"
      },
      "source": [
        "### 1.2.5 Cek Duplikasi data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrv2dUhIfztq"
      },
      "outputs": [],
      "source": [
        "#cek duplikat\n",
        "df.duplicated().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9XK-PdkwgFJ"
      },
      "outputs": [],
      "source": [
        "# melihat duplikasi\n",
        "\n",
        "dupes = df[df.duplicated(keep=False)]\n",
        "dupes.sort_values(by=list(df.columns)).head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdjLbzllxASM"
      },
      "outputs": [],
      "source": [
        "#hapus duplikat\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJwedkRMOM8S"
      },
      "outputs": [],
      "source": [
        "df_duplikasi = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUSgukMMLxYO"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhGR65RYx3oV"
      },
      "source": [
        "### 1.2.6 Cek Distribusi\n",
        "\n",
        "cara paling mudah dan simple melihat distribusi ialah dengan menggunakan histogram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPc371DIx6NR"
      },
      "outputs": [],
      "source": [
        "# Pilih hanya kolom numerik\n",
        "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "#jumlah kolom grid\n",
        "n_cols = 3\n",
        "n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
        "\n",
        "# Buat figure\n",
        "plt.figure(figsize=(n_cols * 3, n_rows * 2))\n",
        "\n",
        "# Loop untuk setiap kolom\n",
        "for i, col in enumerate(numeric_cols, 1):\n",
        "    plt.subplot(n_rows, n_cols, i)\n",
        "    plt.hist(df[col].dropna(), bins=30, edgecolor='black')\n",
        "    plt.title(col)\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkgBx4YhtuQA"
      },
      "source": [
        "lakukan transformasi log untuk kolom yang skeewness right (mayoritas kolom spt itu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kqVQGc0y4Ff"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# daftar kolom yang mau di-log transform\n",
        "right_skewed_cols = [\n",
        "    'aqi', 'o3_8hr', 'nox', 'no2', 'no',\n",
        "    'windspeed', 'pm2.5_avg', 'pm10_avg', 'so2_avg'\n",
        "]\n",
        "\n",
        "LOG_THRESHOLD_MAX = 10\n",
        "LOG_THRESHOLD_MEAN = 2\n",
        "\n",
        "for col in right_skewed_cols:\n",
        "    if col not in df.columns:\n",
        "        print(f\"⚠️ Kolom '{col}' tidak ditemukan di DataFrame, skip.\")\n",
        "        continue\n",
        "\n",
        "    # isi nilai kosong dulu biar gak NaN setelah log\n",
        "    df[col] = df[col].fillna(0)\n",
        "\n",
        "    # buang nilai negatif (ganti jadi 0 biar aman di log1p)\n",
        "    df[col] = df[col].clip(lower=0)\n",
        "\n",
        "    # ambil statistik dasar\n",
        "    max_val = df[col].max()\n",
        "    mean_val = df[col].mean()\n",
        "\n",
        "    # deteksi apakah sudah di-log sebelumnya\n",
        "    if max_val < LOG_THRESHOLD_MAX and mean_val < LOG_THRESHOLD_MEAN:\n",
        "        print(f\"⏭️  Kolom '{col}' kemungkinan SUDAH di-log sebelumnya — dilewati.\")\n",
        "        continue\n",
        "\n",
        "    # lakukan log transform aman\n",
        "    df[col] = np.log1p(df[col])\n",
        "\n",
        "    # pastikan gak ada inf/NaN setelah log\n",
        "    df[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "    print(f\"✅ Log-transform aman diterapkan ke kolom: '{col}' (max={max_val:.2f}, mean={mean_val:.2f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l3AgXSVtuQB"
      },
      "source": [
        "lihat histogram pasca di normalisasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sADi8mxZtuQB"
      },
      "outputs": [],
      "source": [
        "right_skewed_cols = [\n",
        "    'aqi', 'o3_8hr', 'nox', 'no2', 'no',\n",
        "    'windspeed', 'pm2.5_avg', 'pm10_avg', 'so2_avg'\n",
        "]\n",
        "\n",
        "# buat grid histogram\n",
        "n_cols = 3  # jumlah kolom plot per baris\n",
        "n_rows = int(np.ceil(len(right_skewed_cols) / n_cols))\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(right_skewed_cols, 1):\n",
        "    if col in df.columns:\n",
        "        plt.subplot(n_rows, n_cols, i)\n",
        "        plt.hist(df[col].dropna(), bins=30, edgecolor='black')\n",
        "        plt.title(col, fontsize=10)\n",
        "        plt.xlabel(\"Value\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "    else:\n",
        "        print(f\"⚠️ Kolom '{col}' tidak ditemukan di DataFrame — skip.\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUOj23ECtuQC"
      },
      "outputs": [],
      "source": [
        "#lakukan pengarsipan\n",
        "df_transform = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKBatJPHtuQC"
      },
      "source": [
        "### 1.2.7 cek korelasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNsO6vMRtuQC"
      },
      "outputs": [],
      "source": [
        "corr_matrix = df[[\"so2\",\"co\",\"o3\",\"o3_8hr\",\"pm10\",\"pm2.5\",\"no2\",\"nox\",\"no\",\n",
        "        \"windspeed\",\"winddirec\",\"co_8hr\",\"pm2.5_avg\",\"pm10_avg\",\"so2_avg\", \"aqi\"]].corr()\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title(\"Heatmap Korelasi Antar Variabel\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUcHNEUatuQC"
      },
      "source": [
        "dari Map Korelasi diatas, yang akan digunakan dalam membuat model adalah co, so2_avg, windspeed, o3 dan pm2.5_avg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn9pGnxmtuQC"
      },
      "source": [
        "### 1.2.8 Cek Multikolinieritas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta-2K5b0tuQC"
      },
      "outputs": [],
      "source": [
        "cols_to_check = [\"co\", \"so2_avg\", \"windspeed\", \"o3\", \"pm2.5_avg\"]\n",
        "X = df[cols_to_check].copy()\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KLR2ROEtuQC"
      },
      "outputs": [],
      "source": [
        "print(vif_data.sort_values(by=\"VIF\", ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCLrKgcQtuQD"
      },
      "outputs": [],
      "source": [
        "#buat map korelasi hanya untuk kolom yang akan kita gunakan dalam model\n",
        "corr_matrix = df[[\"co\",\"o3\",\"winddirec\",\"so2_avg\", \"pm2.5_avg\", \"aqi\"]].corr()\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title(\"Heatmap Korelasi Antar Variabel\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuw_Co_XtuQD"
      },
      "source": [
        "## 1.3 Membuat Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2Ucma-otuQD"
      },
      "source": [
        "### 1.3.1 definisikan target dan fitur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzcRtSM7eNdE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data_sampemodel.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x5g8HtMmAUa"
      },
      "source": [
        "karena ini merupakan data timeseries, maka akan kita cek terlebih dahulu tahunnya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9cNYH88kozO"
      },
      "outputs": [],
      "source": [
        "#convert data ke datetime\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "df['date'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwOD7tIkmDwn"
      },
      "outputs": [],
      "source": [
        "#lihat range data\n",
        "df[\"date\"].min(), df[\"date\"].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jWtOkzxmINN"
      },
      "source": [
        "karena range data nya dari 15 juli 2019 - 31 agustus 2024, maka untuk split data train adalah tahun 2020-2022 dan data training tahun 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7tFR0VsmKlP"
      },
      "outputs": [],
      "source": [
        "# kita buat kolom khusus untuk tahun\n",
        "df[\"year\"] = df[\"date\"].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61OOJ3s-mLOb"
      },
      "outputs": [],
      "source": [
        "train_df = df[(df[\"year\"] >= 2020) & (df[\"year\"] <= 2022)]\n",
        "test_df  = df[df[\"year\"] == 2023]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJbD2xr3tuQE"
      },
      "outputs": [],
      "source": [
        "X_train = train_df[[\"co\", \"so2_avg\", \"windspeed\", \"o3\", \"pm2.5_avg\"]]\n",
        "y_train = train_df[\"aqi\"]\n",
        "\n",
        "X_test = test_df[[\"co\", \"so2_avg\", \"windspeed\", \"o3\", \"pm2.5_avg\"]]\n",
        "y_test = test_df[\"aqi\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-W_TbQComPVR"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X_train = sm.add_constant(X_train)\n",
        "X_test  = sm.add_constant(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yHsTKZVtuQE"
      },
      "source": [
        "### 1.3.2 print modelnya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NvhfZqdkp9F"
      },
      "outputs": [],
      "source": [
        "X_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fet4BsAgk_JZ"
      },
      "outputs": [],
      "source": [
        "# Hapus semua baris yang punya NaN di X_train\n",
        "X_train = X_train.dropna()\n",
        "\n",
        "# Samain y_train biar indexnya match dengan X_train\n",
        "y_train = y_train.loc[X_train.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90qESJBykFNs"
      },
      "outputs": [],
      "source": [
        "# model OLS (Ordinary Least Squares)\n",
        "model = sm.OLS(y_train, X_train).fit()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dkCNgSxmVF0"
      },
      "source": [
        "prediksi pakai data test (data tahun 2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olSs4QcZmVtr"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bZOsfU8mXVd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse**0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW8eJ0XrzKPa"
      },
      "source": [
        "## 1.4 Uji Asumsi Klasik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-T3kghizSoi"
      },
      "source": [
        "### 1.4.1  Uji Homoskedastisitas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8DHC91ahCML"
      },
      "outputs": [],
      "source": [
        "#uji homoskedastisitas\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "\n",
        "# model = sm.OLS(y, X).fit()\n",
        "# Ambil residual dan variabel independen\n",
        "residuals = model.resid\n",
        "exog = model.model.exog\n",
        "\n",
        "# Lakukan uji Breusch-Pagan\n",
        "bp_test = het_breuschpagan(residuals, exog)\n",
        "\n",
        "# Simpan hasilnya\n",
        "labels = ['Lagrange multiplier statistic', 'p-value',\n",
        "          'f-value', 'f p-value']\n",
        "print(dict(zip(labels, bp_test)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IXVh24UrHZO"
      },
      "outputs": [],
      "source": [
        "#visualisasi homoskedastisitas\n",
        "#sekalian uji linearitas\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Hitung residual dan prediksi\n",
        "residuals = model.resid\n",
        "fitted = model.fittedvalues\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.scatterplot(x=fitted, y=residuals)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.title('Residual vs Fitted Values')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()\n",
        "\n",
        "#heteroskedastisitas ringan\n",
        "#uji linearitas masih cukup terpenuhi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLywfgpNz1Q_"
      },
      "source": [
        "### 1.4.2 Uji Multikolinieritas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKEUfsV3sqsa"
      },
      "outputs": [],
      "source": [
        "#uji multikolinearitas dari data yang dipake di model\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import pandas as pd\n",
        "\n",
        "# Hitung VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "print(vif_data)\n",
        "\n",
        "#udah bagus VIF nya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nad0D9Gvz4MT"
      },
      "source": [
        "### 1.4.3 Uji Normalitas\n",
        "disini kita menggunakan test Jarque Bera Test karena data yang digunakan ialah data Time Series dan Jarque Bera Test lebih cocok untuk data Time series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLjmsqQP0FJv"
      },
      "outputs": [],
      "source": [
        "# statistik jarque bera test\n",
        "from statsmodels.stats.stattools import jarque_bera\n",
        "residual = model.resid\n",
        "jb_stat, jb_pvalue, skew, kurtosis = jarque_bera(residual)\n",
        "\n",
        "print(\"\\n=== UJI NORMALITAS (JARQUE-BERA TEST) ===\")\n",
        "print(f\"Jarque-Bera Statistic : {jb_stat:.4f}\")\n",
        "print(f\"P-Value               : {jb_pvalue:.4f}\")\n",
        "print(f\"Skewness              : {skew:.4f}\")\n",
        "print(f\"Kurtosis              : {kurtosis:.4f}\")\n",
        "\n",
        "# Interpretasi otomatis\n",
        "if jb_pvalue > 0.05:\n",
        "    print(\"✅ Residual berdistribusi normal (p > 0.05)\")\n",
        "else:\n",
        "    print(\"❌ Residual tidak normal (p < 0.05)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lypf1jc90F7D"
      },
      "outputs": [],
      "source": [
        "#visual\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Histogram residual + KDE\n",
        "sns.histplot(residual, kde=True)\n",
        "plt.title(\"Distribusi Residual\")\n",
        "plt.show()\n",
        "\n",
        "# Q-Q plot (normal probability plot)\n",
        "stats.probplot(residual, dist=\"norm\", plot=plt)\n",
        "plt.title(\"Q-Q Plot Residual\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdtlpaow0Ko9"
      },
      "source": [
        "ada sedikit keanehan pada distribusi residualnya, disini nilai nya berkumpul pada rentang -2 hingga 2, salah satu penyebabnya ialah range data yang berbeda jauh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "425YLai70ID_"
      },
      "outputs": [],
      "source": [
        "# Lihat range (max - min) dan standar deviasi\n",
        "X_train.describe().T[[\"min\", \"max\", \"mean\", \"std\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2tjE5NF0PV4"
      },
      "outputs": [],
      "source": [
        "# disini ada keanehan yaitu data min untuk co dan o3 sebesar -999.0, oleh karena itu kita ubah -999.0 menjadi NAN. dan diubah menjadi median\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "cols_to_fix = [\"co\", \"o3\"]  # ganti sesuai kolom yang bermasalah\n",
        "\n",
        "# Ganti -999 jadi NaN di semua kolom\n",
        "X_train[cols_to_fix] = X_train[cols_to_fix].replace(-999, np.nan)\n",
        "X_test[cols_to_fix] = X_test[cols_to_fix].replace(-999, np.nan)\n",
        "\n",
        "# Isi NaN dengan median (pakai median dari TRAIN)\n",
        "for col in cols_to_fix:\n",
        "    median_val = X_train[col].median()\n",
        "    X_train[col].fillna(median_val, inplace=True)\n",
        "    X_test[col].fillna(median_val, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZNBE_gf0Rbc"
      },
      "outputs": [],
      "source": [
        "#kita test lagi dengan jerque bera test\n",
        "model = sm.OLS(y_train, X_train).fit()\n",
        "residual = model.resid\n",
        "jb_stat, jb_pvalue, skew, kurtosis = jarque_bera(residual)\n",
        "\n",
        "print(\"\\n=== UJI NORMALITAS (JARQUE-BERA TEST) ===\")\n",
        "print(f\"Jarque-Bera Statistic : {jb_stat:.4f}\")\n",
        "print(f\"P-Value               : {jb_pvalue:.4f}\")\n",
        "print(f\"Skewness              : {skew:.4f}\")\n",
        "print(f\"Kurtosis              : {kurtosis:.4f}\")\n",
        "\n",
        "# Interpretasi otomatis\n",
        "if jb_pvalue > 0.05:\n",
        "    print(\"✅ Residual berdistribusi normal (p > 0.05)\")\n",
        "else:\n",
        "    print(\"❌ Residual tidak normal (p < 0.05)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN9auZOwmBnk"
      },
      "outputs": [],
      "source": [
        "(X_train == 0).sum() / len(X_train) * 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-fEvoexm7Pr"
      },
      "outputs": [],
      "source": [
        "# Transform sqrt langsung pada kolom asli\n",
        "X_train[\"so2_sqrt\"] = np.sqrt(X_train[\"so2_avg\"])\n",
        "\n",
        "# Tambahkan fitur indikator zero\n",
        "X_train[\"so2_zero\"] = (X_train[\"so2_avg\"] == 0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3kY7paJnPXv"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.drop(columns=[\"so2_avg\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZP_2KWBnRPN"
      },
      "outputs": [],
      "source": [
        "model = sm.OLS(y_train, X_train).fit()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI7GvescnmTe"
      },
      "outputs": [],
      "source": [
        "#visual\n",
        "sns.histplot(model.resid, bins=50, kde=True)\n",
        "plt.title(\"Distribusi Residual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KucDg9yun9KA"
      },
      "outputs": [],
      "source": [
        "res = model.resid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDbnlhQjn_I9"
      },
      "outputs": [],
      "source": [
        "lower = res.quantile(0.01)\n",
        "upper = res.quantile(0.99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfklgXvzoA5P"
      },
      "outputs": [],
      "source": [
        "mask = (res >= lower) & (res <= upper)\n",
        "\n",
        "X_train_trim = X_train[mask]\n",
        "y_train_trim = y_train[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdDxpwjHoCjq"
      },
      "outputs": [],
      "source": [
        "model_trim = sm.OLS(y_train_trim, X_train_trim).fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vk5rBAfRoEHJ"
      },
      "outputs": [],
      "source": [
        "sns.histplot(model_trim.resid, bins=50, kde=True)\n",
        "plt.title(\"Residual setelah trimming outlier\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD3EXllioMeg"
      },
      "source": [
        "Udah aman"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_68mrGBT2Ke"
      },
      "source": [
        "# 2. MEMBUAT PERBANDINGAN ANTARA MODEL DENGAN VARIABEL LENGKAP DENGAN VARIABEL PILIHAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xbcq1rde91H"
      },
      "source": [
        "## 2.1 pemilihan variabel, split data, deklarasi x dan y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2zQ8clUT7D-"
      },
      "outputs": [],
      "source": [
        "#perbandingan model dengan variabel lengkap\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# 1. Buat kolom tahun dari date\n",
        "df[\"year\"] = df[\"date\"].dt.year\n",
        "\n",
        "# 2. Split train-test berdasarkan tahun\n",
        "train_df_v = df[(df[\"year\"] >= 2020) & (df[\"year\"] <= 2022)]\n",
        "test_df_v  = df[df[\"year\"] == 2023]\n",
        "\n",
        "# 3. Daftar kolom yang TIDAK boleh masuk sebagai predictor\n",
        "exclude_cols = [\n",
        "    \"date\", \"sitename\", \"county\", \"aqi\", \"pollutant\", \"status\",\n",
        "    \"unit\", \"longitude\", \"latitude\", \"siteid\", \"year\"\n",
        "]\n",
        "\n",
        "# 4. Pilih semua kolom numerik kecuali yang dikecualikan\n",
        "features = [\n",
        "    col for col in train_df_v.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
        "    if col not in exclude_cols\n",
        "]\n",
        "\n",
        "print(\"Fitur yang dipakai sebagai X:\")\n",
        "print(features)\n",
        "\n",
        "# 5. Buat X dan y\n",
        "X_train_v = train_df_v[features]\n",
        "y_train_v = train_df_v[\"aqi\"]\n",
        "\n",
        "X_test_v  = test_df_v[features]\n",
        "y_test_v  = test_df_v[\"aqi\"]\n",
        "\n",
        "# 6. Tambahkan konstanta\n",
        "X_train_v = sm.add_constant(X_train_v)\n",
        "X_test_v  = sm.add_constant(X_test_v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmFKCfYOe4wz"
      },
      "source": [
        "## 2.1 MEMBUAT MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ufl8sl9fWO6"
      },
      "source": [
        "### 2.1.1 memilih model ols dan print summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZvMVE9hT8Ev"
      },
      "outputs": [],
      "source": [
        "# model OLS (Ordinary Least Squares)\n",
        "model_v = sm.OLS(y_train_v, X_train_v).fit()\n",
        "print(model_v.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5YvgJShfPnS"
      },
      "source": [
        "### 2.1.2 deklarasi y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0EILJE1T-Er"
      },
      "outputs": [],
      "source": [
        "y_pred_v = model_v.predict(X_test_v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5yTDq59fd4X"
      },
      "source": [
        "### 2.1.3 Evaluasi Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RUzDvgaT_0D"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test_v, y_pred_v)\n",
        "rmse = mse**0.5\n",
        "r2 = r2_score(y_test_v, y_pred_v)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_SAFkL_UEZM"
      },
      "source": [
        "**PERBANDINGAN**\n",
        "\n",
        "R-Squared: Model lengkap menjelaskan persentase variasi yang lebih besar pada variabel dependen (aqi)\n",
        "\n",
        "\n",
        "F-statistic: kedua model secara keseluruhan sangat signifikan (Prob (F-statistic) = 0.00). Nilai F yang lebih besar pada Model dengan 5 variabel (meskipun memiliki $R^2$ lebih kecil) menunjukkan bahwa variabelnya secara kolektif menjelaskan variasi yang jauh lebih besar relatif terhadap jumlah variabelnya yang lebih kecil.\n",
        "\n",
        "\n",
        "Condition Number: Kekhawatiran Utama. Angka di atas 30 menunjukkan multikolinearitas yang kuat. Model lengkap memiliki 4110, menunjukkan masalah multikolinearitas yang sangat parah, yang dapat membuat koefisien menjadi tidak stabil dan sulit diinterpretasikan. Model dengan 5 variabel juga memiliki Cond. No. yang tinggi (179) tetapi jauh lebih rendah daripada Model 1, mengindikasikan bahwa pengurangan variabel telah secara signifikan mengurangi tingkat multikolinearitas, meskipun masih ada.\n",
        "\n",
        "\n",
        "**KESIMPULAN**\n",
        "1. Daya Penjelas (Fit): Model lengkap lebih unggul dalam hal $R^2$ dan Adjusted $R^2$ (0.795 vs 0.764) dan memiliki nilai AIC/BIC yang jauh lebih rendah, menunjukkan bahwa model tersebut secara statistik merupakan model yang lebih baik untuk menjelaskan variasi variabel dependen ($aqi$).\n",
        "2. Masalah Kualitas Model (Multikolinearitas): Model lengkap mengalami masalah yang jauh lebih parah dengan multikolinearitas (Cond. No. $4110$) dibandingkan Model dengan 5 variabel (Cond. No. 179). Hal ini ditunjukkan oleh koefisien $co$ yang berubah tanda secara drastis antara kedua model, yang merupakan tanda klasik dari ketidakstabilan koefisien akibat multikolinearitas yang tinggi.\n",
        "3. Keterbatasan Umum: Kedua model menunjukkan bukti kuat adanya autokorelasi (Durbin-Watson < 2) dan residual yang tidak berdistribusi normal (Prob(Omnibus) = 0.000).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csrfZ4MZaNX_"
      },
      "source": [
        "-------------------\n",
        "\n",
        "MODEL OLS & MLE COMPARISON\n",
        "\n",
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70DO0B5zaNYA"
      },
      "source": [
        "Komparasi 16 Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrUKW8WBaNYA"
      },
      "outputs": [],
      "source": [
        "# model OLS (Ordinary Least Squares)\n",
        "model_v = sm.OLS(y_train_v, X_train_v).fit()\n",
        "print(model_v.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ5MzeMSaNYB"
      },
      "outputs": [],
      "source": [
        "model_mle_v = sm.GLM(y_train_v, X_train_v, family=sm.families.Gaussian()).fit()\n",
        "print(model_mle_v.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjZ4GiBQaNYB"
      },
      "outputs": [],
      "source": [
        "comparison = pd.DataFrame({\n",
        "    \"Model\": [\"OLS\", \"MLE\"],\n",
        "    \"Parameters\": [len(model_v.params), len(model_mle_v.params)],\n",
        "    \"AIC\": [model_v.aic, model_mle_v.aic],\n",
        "    \"BIC\": [model_v.bic, model_mle_v.bic],\n",
        "    \"Log-Likelihood\": [model_v.llf, model_mle_v.llf]\n",
        "})\n",
        "print(comparison)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtBH94fDaNYB"
      },
      "source": [
        "Komparasi 7 Parameter ( PM2.5 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGxkp2ataNYC"
      },
      "outputs": [],
      "source": [
        "# model OLS (Ordinary Least Squares)\n",
        "model = sm.OLS(y_train, X_train).fit()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS33MiRdaNYC"
      },
      "outputs": [],
      "source": [
        "model_mle_6Parameter = sm.GLM(y_train, X_train, family=sm.families.Gaussian()).fit()\n",
        "print(model_mle_6Parameter.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbpfYbCPaNYC"
      },
      "outputs": [],
      "source": [
        "comparison = pd.DataFrame({\n",
        "    \"Model\": [\"OLS\", \"MLE\"],\n",
        "    \"Parameters\": [len(model.params), len(model_mle_6Parameter.params)],\n",
        "    \"AIC\": [model.aic, model_mle_6Parameter.aic],\n",
        "    \"BIC\": [model.bic, model_mle_6Parameter.bic],\n",
        "    \"Log-Likelihood\": [model.llf, model_mle_6Parameter.llf]\n",
        "})\n",
        "print(comparison)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PifA3n5RaNYC"
      },
      "source": [
        "Baik OLS maupun MLE menghasilkan AIC dan log-likelihood yang identik. Ini menunjukkan bahwa kedua metode memberikan kualitas prediksi dan kompleksitas model yang sama. Dengan demikian, tidak terdapat perbedaan performa antara OLS dan MLE pada dataset ini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UtPU3TzaNYC"
      },
      "source": [
        "-----------------------------------------------------\n",
        "\n",
        "PM2.5 -> PM10 7 Parameter\n",
        "\n",
        "-----------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrzgTcBCaNYC"
      },
      "outputs": [],
      "source": [
        "# --- Fitur PM10 ---\n",
        "fitur_pm10 = [\"co\", \"so2_avg\", \"windspeed\", \"o3\", \"pm10_avg\"]\n",
        "\n",
        "# --- Train set ---\n",
        "X_train_pm10 = train_df[fitur_pm10].copy()\n",
        "y_train_pm10 = train_df[\"aqi\"]\n",
        "\n",
        "# Transformasi SO2\n",
        "X_train_pm10[\"so2_sqrt\"] = np.sqrt(X_train_pm10[\"so2_avg\"])\n",
        "X_train_pm10[\"so2_zero\"] = (X_train_pm10[\"so2_avg\"] == 0).astype(int)\n",
        "X_train_pm10 = X_train_pm10.drop(columns=[\"so2_avg\"])\n",
        "\n",
        "# --- Test set ---\n",
        "X_test_pm10 = test_df[fitur_pm10].copy()\n",
        "y_test_pm10 = test_df[\"aqi\"]\n",
        "\n",
        "# Transformasi SO2 sama seperti train\n",
        "X_test_pm10[\"so2_sqrt\"] = np.sqrt(X_test_pm10[\"so2_avg\"])\n",
        "X_test_pm10[\"so2_zero\"] = (X_test_pm10[\"so2_avg\"] == 0).astype(int)\n",
        "X_test_pm10 = X_test_pm10.drop(columns=[\"so2_avg\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfK9KlSXaNYC"
      },
      "outputs": [],
      "source": [
        "X_train_pm10 = sm.add_constant(X_train_pm10)\n",
        "X_test_pm10  = sm.add_constant(X_test_pm10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys0L7yVUaNYD"
      },
      "outputs": [],
      "source": [
        "# OLS\n",
        "model_ols_pm10 = sm.OLS(y_train_pm10, X_train_pm10).fit()\n",
        "print(model_ols_pm10.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8-zMYlAaNYD"
      },
      "outputs": [],
      "source": [
        "# MLE Gaussian\n",
        "model_mle_pm10 = sm.GLM(y_train_pm10, X_train_pm10, family=sm.families.Gaussian()).fit()\n",
        "print(model_mle_pm10.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c_lQM2QaNYD"
      },
      "outputs": [],
      "source": [
        "comparison_pm10 = pd.DataFrame({\n",
        "    \"Model\": [\"OLS\", \"MLE\"],\n",
        "    \"Parameters\": [len(model_ols_pm10.params), len(model_mle_pm10.params)],\n",
        "    \"AIC\": [model_ols_pm10.aic, model_mle_pm10.aic],\n",
        "    \"BIC\": [model_ols_pm10.bic, model_mle_pm10.bic],\n",
        "    \"Log-Likelihood\": [model_ols_pm10.llf, model_mle_pm10.llf]\n",
        "})\n",
        "\n",
        "print(comparison_pm10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lniWnnTHcFWe"
      },
      "source": [
        "# 3. MEMBUAT MODEL TANPA MELAKUKAN TRANSFORMASI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq9ytOwxfiVs"
      },
      "source": [
        "##3. 1 Deklarasi variabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw2gYNf4cODi"
      },
      "outputs": [],
      "source": [
        "df_no_log = df_duplikasi.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iLa1p8QcQGT"
      },
      "outputs": [],
      "source": [
        "df_no_log[\"date\"] = pd.to_datetime(df_no_log[\"date\"], errors=\"coerce\")\n",
        "\n",
        "# bikin kolom tahun\n",
        "df_no_log[\"year\"] = df_no_log[\"date\"].dt.year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJKjfzVefyZW"
      },
      "source": [
        "## 3.2 melakukan split data training dan testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ2afM3kcTAk"
      },
      "outputs": [],
      "source": [
        "train_df = df_no_log[(df_no_log[\"year\"] >= 2020) & (df_no_log[\"year\"] <= 2022)]\n",
        "test_df  = df_no_log[df_no_log[\"year\"] == 2023]\n",
        "\n",
        "print(\"Jumlah data train :\", len(train_df))\n",
        "print(\"Jumlah data test  :\", len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-S2nOYhCcUVB"
      },
      "outputs": [],
      "source": [
        "fitur = [\"co\", \"so2_avg\", \"windspeed\", \"o3\", \"pm2.5_avg\"]\n",
        "\n",
        "X_train = train_df[fitur]\n",
        "y_train = train_df[\"aqi\"]\n",
        "\n",
        "X_test = test_df[fitur]\n",
        "y_test = test_df[\"aqi\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfPJtkhBcV5-"
      },
      "outputs": [],
      "source": [
        "X_train = sm.add_constant(X_train)\n",
        "X_test  = sm.add_constant(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcoYUkNlf-dY"
      },
      "source": [
        "## 3.3 Deklarasi model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqEd6T1RcXPx"
      },
      "outputs": [],
      "source": [
        "model_no_log = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "print(model_no_log.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bcqc337f_s5"
      },
      "source": [
        "### 3.3.1 mencari y preddict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-noj1fl1cYib"
      },
      "outputs": [],
      "source": [
        "y_pred = model_raw.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsxKHfFBgD4D"
      },
      "source": [
        "### 3.3.2 evaluasi model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR2nJsrIcaBI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse**0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"===== Evaluasi Model Tanpa Transformasi =====\")\n",
        "print(\"MSE :\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R²  :\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTczrlqwgG7u"
      },
      "source": [
        "3.3.3 melihat range variabel y untuk melihat apakah nilai MSE dan RMSE buruk atau baik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXOdjxqocb6c"
      },
      "source": [
        "Untuk mengetahui baik buruknya MSE maka harus di cari dulu nilai MIN dan MAX dari AQI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs7Nqpx_cpic"
      },
      "outputs": [],
      "source": [
        "print(\"===== MIN–MAX AQI SELURUH DATA =====\")\n",
        "print(\"Min AQI :\", df_no_log['aqi'].min())\n",
        "print(\"Max AQI :\", df_no_log['aqi'].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8m76rGLcgcP"
      },
      "source": [
        "**KESIMPULAN**\n",
        "\n",
        "R-squared 0.913 (train) dan R² test 0.901, membuktikan model mampu menjelaskan sebagian besar variasi AQI. Semua variabel signifikan secara statistik, dengan PM2.5 sebagai prediktor paling dominan. RMSE hanya 8.10, jauh lebih kecil dari rentang AQI (−1 sampai 467), sehingga error model relatif sangat kecil. Meskipun bhasilnya bagus, distribusi residual sangat skewed, sehingga model mungkin diuntungkan jika dilakukan transformasi log pada variabel yang right-skewed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v1ytfJJtuQE"
      },
      "source": [
        "# STOPPPP"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}